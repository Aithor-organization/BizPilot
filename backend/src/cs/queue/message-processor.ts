import { Processor, WorkerHost } from '@nestjs/bullmq';
import { Logger } from '@nestjs/common';
import { Job } from 'bullmq';
import { PrismaService } from '../../prisma/prisma.service';
import { InjectQueue } from '@nestjs/bullmq';
import { Queue } from 'bullmq';
import { RagService } from '../knowledge/rag.service';
import { LlmService } from '../knowledge/llm.service';
import { CreditService } from '../credit/credit.service';

interface MessageJobData {
  messageId: string;
  conversationId: string;
  tenantId: string;
  content: string;
}

@Processor('message-processing')
export class MessageProcessor extends WorkerHost {
  private readonly logger = new Logger(MessageProcessor.name);

  constructor(
    private prisma: PrismaService,
    @InjectQueue('brain-learning') private brainQueue: Queue,
    private ragService: RagService,
    private llmService: LlmService,
    private creditService: CreditService,
  ) {
    super();
  }

  async process(job: Job<MessageJobData>): Promise<void> {
    const { messageId, conversationId, tenantId, content } = job.data;
    this.logger.log(`Processing message ${messageId} for tenant ${tenantId}`);

    try {
      // 1. Search Brain patterns
      const patterns = await this.prisma.odBrainPattern.findMany({
        where: {
          tenantId,
          type: 'SUCCESS_PATTERN',
        },
        orderBy: { confidence: 'desc' },
        take: 10,
      });

      // 2. Calculate confidence from pattern matching
      let confidence = 0;
      let matchedPattern = null;
      const keywords = content.toLowerCase().split(/\s+/).filter((w) => w.length > 2);

      for (const pattern of patterns) {
        const patternKeywords = pattern.context.toLowerCase().split(/\s+/);
        const overlap = keywords.filter((k) => patternKeywords.some((pk) => pk.includes(k) || k.includes(pk)));
        const score = keywords.length > 0 ? (overlap.length / keywords.length) * pattern.confidence : 0;
        if (score > confidence) {
          confidence = score;
          matchedPattern = pattern;
        }
      }

      // 3. Generate response
      let botResponse: string;

      if (matchedPattern && confidence >= 0.7) {
        // High confidence pattern match - use cached response
        botResponse = matchedPattern.content;
        await this.prisma.odBrainPattern.update({
          where: { id: matchedPattern.id },
          data: { hitCount: { increment: 1 }, lastHitAt: new Date() },
        });
      } else {
        // Low confidence - use RAG + LLM for dynamic response
        const llmResult = await this.generateLlmResponse(tenantId, content, patterns);

        if (llmResult) {
          botResponse = llmResult.response;
          confidence = llmResult.confidence;

          // Deduct credits for LLM usage
          await this.tryDeductCredits(tenantId, 1, 'AI ìë™ ì‘ë‹µ ìƒì„±', messageId, 'MESSAGE_AI_RESPONSE');
        } else {
          // Demo template response - keyword-based smart reply
          const templateResult = this.getDemoTemplateResponse(content);
          botResponse = templateResult.response;
          confidence = templateResult.confidence;
        }
      }

      // 4. Create bot message
      await this.prisma.odMessage.create({
        data: {
          conversationId,
          senderType: 'BOT',
          content: botResponse,
          confidence,
        },
      });

      // 5. Handle based on confidence
      if (confidence >= 0.7) {
        this.logger.log(`Auto-responded to ${conversationId} (confidence: ${confidence.toFixed(2)})`);
      } else if (confidence >= 0.5) {
        // Medium confidence - bot responded but flag for agent review
        await this.prisma.odConversation.update({
          where: { id: conversationId },
          data: { status: 'ASSIGNED', priority: 'NORMAL' },
        });
        this.logger.log(`Bot responded with review needed for ${conversationId} (confidence: ${confidence.toFixed(2)})`);
      } else {
        // Low confidence - escalate
        await this.prisma.odConversation.update({
          where: { id: conversationId },
          data: { status: 'ASSIGNED', priority: 'HIGH' },
        });
        this.logger.log(`Escalated ${conversationId} (confidence: ${confidence.toFixed(2)})`);
      }
    } catch (error) {
      this.logger.error(`Failed to process message ${messageId}`, error);
      throw error;
    }
  }

  private async generateLlmResponse(
    tenantId: string,
    query: string,
    brainPatterns: { content: string; confidence: number }[],
  ): Promise<{ response: string; confidence: number } | null> {
    if (!this.llmService.isAvailable) return null;

    try {
      // Search RAG for relevant knowledge
      let ragContext: string[] = [];
      try {
        const ragResults = await this.ragService.search(tenantId, query, 3);
        ragContext = ragResults
          .filter((r) => r.similarity > 0.3)
          .map((r) => r.content);
      } catch {
        // RAG search may fail if no embeddings exist yet
        this.logger.debug('RAG search returned no results or failed');
      }

      // Get relevant brain patterns for context
      const patternContext = brainPatterns
        .filter((p) => p.confidence >= 0.5)
        .slice(0, 3)
        .map((p) => p.content);

      // Generate LLM response
      const result = await this.llmService.generateResponse({
        query,
        ragContext: ragContext.length > 0 ? ragContext : undefined,
        brainPatterns: patternContext.length > 0 ? patternContext : undefined,
      });

      if (!result || !result.content) return null;

      // Calculate confidence based on context availability
      let responseConfidence = 0.6; // Base LLM confidence
      if (ragContext.length > 0) responseConfidence += 0.1; // Boosted by RAG
      if (patternContext.length > 0) responseConfidence += 0.05; // Boosted by patterns

      return {
        response: result.content,
        confidence: Math.min(0.85, responseConfidence),
      };
    } catch (error) {
      this.logger.error('LLM response generation failed', error);
      return null;
    }
  }

  private getDemoTemplateResponse(content: string): { response: string; confidence: number } {
    const text = content.toLowerCase();

    const templates: { keywords: string[]; response: string; confidence: number }[] = [
      // ê°€ê²©/ë¹„ìš© ë¬¸ì˜
      {
        keywords: ['ê°€ê²©', 'ì–¼ë§ˆ', 'ë¹„ìš©', 'ìš”ê¸ˆ', 'ê¸ˆì•¡', 'í”„ë¼ì´ìŠ¤', 'price'],
        response:
          'ì•ˆë…•í•˜ì„¸ìš”! ë¸”ë£¸ í—¤ì–´ì‚´ë¡± ê°€ê²© ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤ ğŸ˜Š\n\n' +
          'âœ‚ï¸ ì»¤íŠ¸: ì—¬ì„± 25,000ì› / ë‚¨ì„± 18,000ì›\n' +
          'ğŸ’‡ íŒ: 80,000ì›~150,000ì› (ê¸¸ì´ë³„ ìƒì´)\n' +
          'ğŸ¨ ì—¼ìƒ‰: 70,000ì›~120,000ì›\n' +
          'ğŸ’† í´ë¦¬ë‹‰/ì¼€ì–´: 30,000ì›~80,000ì›\n\n' +
          'ì •í™•í•œ ê¸ˆì•¡ì€ ëª¨ë°œ ìƒíƒœì™€ ê¸¸ì´ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”. ë°©ë¬¸ ìƒë‹´ ì‹œ ìì„¸íˆ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”!',
        confidence: 0.88,
      },
      // ì˜ˆì•½ ë¬¸ì˜
      {
        keywords: ['ì˜ˆì•½', 'ì˜ˆì•½í•˜ê³ ', 'ì˜ˆì•½í• ', 'ì˜ˆì•½ê°€ëŠ¥', 'ë¶€í‚¹', 'booking', 'ì¡ê³ '],
        response:
          'ë„¤, ì˜ˆì•½ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ˜Š\n\n' +
          'ğŸ“… ì›í•˜ì‹œëŠ” ë‚ ì§œì™€ ì‹œê°„ì„ ë§ì”€í•´ì£¼ì‹œë©´ ë°”ë¡œ í™•ì¸í•´ë“œë¦´ê²Œìš”.\n' +
          'í˜„ì¬ ì´ë²ˆ ì£¼ í‰ì¼ ì˜¤í›„ì— ì—¬ìœ ê°€ ìˆìŠµë‹ˆë‹¤.\n\n' +
          'ì›í•˜ì‹œëŠ” ì‹œìˆ ê³¼ ë‹´ë‹¹ ë””ìì´ë„ˆê°€ ìˆìœ¼ì‹œë©´ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”!\n' +
          '(ì˜¨ë¼ì¸ ì˜ˆì•½ì€ í™ˆí˜ì´ì§€ì—ì„œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤)',
        confidence: 0.91,
      },
      // ì˜ì—…ì‹œê°„
      {
        keywords: ['ì˜ì—…ì‹œê°„', 'ì˜¤í”ˆ', 'ëª‡ì‹œ', 'ìš´ì˜ì‹œê°„', 'ì–¸ì œê¹Œì§€', 'ë§ˆê°', 'íœ´ë¬´', 'ì‰¬ëŠ”ë‚ '],
        response:
          'ë¸”ë£¸ í—¤ì–´ì‚´ë¡± ì˜ì—…ì‹œê°„ ì•ˆë‚´ì…ë‹ˆë‹¤ ğŸ•\n\n' +
          'ğŸ“ í‰ì¼: ì˜¤ì „ 10:00 ~ ì˜¤í›„ 8:00\n' +
          'ğŸ“ í† ìš”ì¼: ì˜¤ì „ 10:00 ~ ì˜¤í›„ 7:00\n' +
          'ğŸ“ ì¼ìš”ì¼: ì˜¤ì „ 11:00 ~ ì˜¤í›„ 6:00\n' +
          'ğŸ“ ì •ê¸° íœ´ë¬´: ë§¤ì£¼ ì›”ìš”ì¼\n\n' +
          'ë§ˆì§€ë§‰ ì ‘ìˆ˜ëŠ” ë§ˆê° 1ì‹œê°„ ì „ê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤!',
        confidence: 0.92,
      },
      // ì»¤íŠ¸
      {
        keywords: ['ì»¤íŠ¸', 'ì»·íŠ¸', 'ìë¥´', 'ì˜ë¼', 'ë¨¸ë¦¬ì¹´ë½', 'ë‹¨ë°œ', 'ìˆì»·', 'cut'],
        response:
          'ì»¤íŠ¸ ì‹œìˆ  ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤ âœ‚ï¸\n\n' +
          'ì—¬ì„± ì»¤íŠ¸: 25,000ì› (ìƒ´í‘¸+ë“œë¼ì´ í¬í•¨)\n' +
          'ë‚¨ì„± ì»¤íŠ¸: 18,000ì› (ìƒ´í‘¸+ë“œë¼ì´ í¬í•¨)\n' +
          'ì–´ë¦°ì´ ì»¤íŠ¸: 15,000ì›\n\n' +
          'ë””ìì´ë„ˆì™€ ìƒë‹´ í›„ ê³ ê°ë‹˜ì˜ ì–¼êµ´í˜•ê³¼ ë¼ì´í”„ìŠ¤íƒ€ì¼ì— ë§ëŠ” ìŠ¤íƒ€ì¼ì„ ì œì•ˆí•´ë“œë ¤ìš”. ì˜ˆì•½í•˜ì‹œê² ì–´ìš”?',
        confidence: 0.87,
      },
      // íŒ
      {
        keywords: ['íŒ', 'íŒŒë§ˆ', 'ì›¨ì´ë¸Œ', 'ë³¼ë¥¨', 'ì…‹íŒ…', 'perm'],
        response:
          'íŒ ì‹œìˆ  ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤ ğŸ’‡â€â™€ï¸\n\n' +
          'ë””ì§€í„¸ íŒ: 80,000ì›~\n' +
          'ì…‹íŒ… íŒ: 90,000ì›~\n' +
          'ë³¼ë¥¨ ë§¤ì§: 100,000ì›~\n' +
          'ë‹¤ìš´ íŒ (ë‚¨ì„±): 40,000ì›~\n\n' +
          'ëª¨ë°œ ê¸¸ì´ì™€ ìƒíƒœì— ë”°ë¼ ê°€ê²©ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”. ì‹œìˆ  ì‹œê°„ì€ ì•½ 2~3ì‹œê°„ ì†Œìš”ë©ë‹ˆë‹¤. ì˜ˆì•½ ë„ì™€ë“œë¦´ê¹Œìš”?',
        confidence: 0.86,
      },
      // ì—¼ìƒ‰
      {
        keywords: ['ì—¼ìƒ‰', 'ì»¬ëŸ¬', 'íƒˆìƒ‰', 'ìƒ‰ê¹”', 'ë¸”ë¦¬ì¹˜', 'í•˜ì´ë¼ì´íŠ¸', 'color'],
        response:
          'ì—¼ìƒ‰ ì‹œìˆ  ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤ ğŸ¨\n\n' +
          'ì „ì²´ ì—¼ìƒ‰: 70,000ì›~\n' +
          'ë¿Œë¦¬ ì—¼ìƒ‰: 50,000ì›~\n' +
          'í•˜ì´ë¼ì´íŠ¸/ë°œë ˆì•„ì¥¬: 100,000ì›~\n' +
          'íƒˆìƒ‰: 60,000ì›~/1íšŒ\n\n' +
          'í˜„ì¬ íŠ¸ë Œë“œ ì»¬ëŸ¬ì™€ ê³ ê°ë‹˜ í”¼ë¶€í†¤ì— ë§ëŠ” ìƒ‰ìƒì„ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ìƒë‹´ ì˜ˆì•½í•˜ì‹œê² ì–´ìš”?',
        confidence: 0.85,
      },
      // ì¼€ì–´/íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸
      {
        keywords: ['ì¼€ì–´', 'íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸', 'í´ë¦¬ë‹‰', 'ì†ìƒ', 'ë‘í”¼', 'ì˜ì–‘', 'ê´€ë¦¬'],
        response:
          'í—¤ì–´ ì¼€ì–´ í”„ë¡œê·¸ë¨ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤ ğŸ’†\n\n' +
          'ê¸°ë³¸ íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸: 30,000ì›\n' +
          'í”„ë¦¬ë¯¸ì—„ í´ë¦¬ë‹‰: 50,000ì›\n' +
          'ë‘í”¼ ì¼€ì–´: 40,000ì›\n' +
          'ì†ìƒ ëª¨ë°œ ì§‘ì¤‘ ì¼€ì–´: 80,000ì›\n\n' +
          'ì‹œìˆ  ì „í›„ ì¼€ì–´ë¥¼ í•¨ê»˜ í•˜ì‹œë©´ 10% í• ì¸ í˜œíƒì´ ìˆì–´ìš”!',
        confidence: 0.84,
      },
      // ìœ„ì¹˜/ì£¼ì†Œ/ì˜¤ì‹œëŠ”ê¸¸
      {
        keywords: ['ìœ„ì¹˜', 'ì£¼ì†Œ', 'ì–´ë””', 'ì˜¤ì‹œëŠ”ê¸¸', 'ê¸¸', 'ì°¾ì•„ê°€', 'ì£¼ì°¨', 'ì§€í•˜ì² '],
        response:
          'ë¸”ë£¸ í—¤ì–´ì‚´ë¡± ì˜¤ì‹œëŠ” ê¸¸ ì•ˆë‚´ì…ë‹ˆë‹¤ ğŸ“\n\n' +
          'ì£¼ì†Œ: ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™ 123-45 ë¸”ë£¸ë¹Œë”© 2ì¸µ\n' +
          'ğŸš‡ ì§€í•˜ì² : ì—­ì‚¼ì—­ 3ë²ˆ ì¶œêµ¬ì—ì„œ ë„ë³´ 3ë¶„\n' +
          'ğŸš— ì£¼ì°¨: ê±´ë¬¼ ì§€í•˜ì£¼ì°¨ì¥ ì´ìš© ê°€ëŠ¥ (2ì‹œê°„ ë¬´ë£Œ)\n\n' +
          'ê¸¸ ì°¾ê¸° ì–´ë ¤ìš°ì‹œë©´ ì „í™”ì£¼ì„¸ìš”! ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í•´ë“œë¦´ê²Œìš” â˜ºï¸',
        confidence: 0.90,
      },
      // ì¸ì‚¬/ê°ì‚¬
      {
        keywords: ['ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ê³ ë§™', 'ì˜ë', 'ì¢‹ì•„', 'ìµœê³ ', 'ë§Œì¡±'],
        response:
          'ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ˜Š ë¸”ë£¸ í—¤ì–´ì‚´ë¡±ì„ ì°¾ì•„ì£¼ì…”ì„œ ì •ë§ ê¸°ì©ë‹ˆë‹¤.\n' +
          'í•­ìƒ ìµœìƒì˜ ì„œë¹„ìŠ¤ë¡œ ë³´ë‹µí•˜ê² ìŠµë‹ˆë‹¤.\n\n' +
          'ë‹¤ë¥¸ ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ì£¼ì„¸ìš”!',
        confidence: 0.82,
      },
      // ì¸ì‚¬/ì•ˆë…•
      {
        keywords: ['ì•ˆë…•', 'í•˜ì´', 'í—¬ë¡œ', 'hello', 'hi', 'ë°˜ê°‘'],
        response:
          'ì•ˆë…•í•˜ì„¸ìš”! ë¸”ë£¸ í—¤ì–´ì‚´ë¡±ì…ë‹ˆë‹¤ ğŸŒ¸\n' +
          'ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n\n' +
          'ğŸ’‡ ì‹œìˆ  ì˜ˆì•½\n' +
          'ğŸ’° ê°€ê²© ë¬¸ì˜\n' +
          'ğŸ“ ì˜¤ì‹œëŠ” ê¸¸\n' +
          'ğŸ“ ê¸°íƒ€ ë¬¸ì˜\n\n' +
          'í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”!',
        confidence: 0.85,
      },
      // ì·¨ì†Œ/ë³€ê²½
      {
        keywords: ['ì·¨ì†Œ', 'ë³€ê²½', 'ë°”ê¾¸', 'ë°”ê¿€', 'ì¼ì •', 'ë¯¸ë£¨', 'ìº”ìŠ¬'],
        response:
          'ì˜ˆì•½ ë³€ê²½/ì·¨ì†Œ ì•ˆë‚´ì…ë‹ˆë‹¤ ğŸ“‹\n\n' +
          'â€¢ ì˜ˆì•½ ë³€ê²½: ì‹œìˆ  í•˜ë£¨ ì „ê¹Œì§€ ë¬´ë£Œ ë³€ê²½ ê°€ëŠ¥\n' +
          'â€¢ ì˜ˆì•½ ì·¨ì†Œ: ë‹¹ì¼ ì·¨ì†Œ ì‹œ ì·¨ì†Œ ìˆ˜ìˆ˜ë£Œê°€ ë°œìƒí•  ìˆ˜ ìˆì–´ìš”\n\n' +
          'ë³€ê²½í•˜ì‹¤ ì˜ˆì•½ ë‚ ì§œì™€ ì„±í•¨ì„ ì•Œë ¤ì£¼ì‹œë©´ ë°”ë¡œ ì²˜ë¦¬í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!',
        confidence: 0.83,
      },
      // ì´ë²¤íŠ¸/í• ì¸
      {
        keywords: ['ì´ë²¤íŠ¸', 'í• ì¸', 'í”„ë¡œëª¨ì…˜', 'ì¿ í°', 'í˜œíƒ', 'íŠ¹ê°€', 'ì„¸ì¼'],
        response:
          'í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤ ğŸ‰\n\n' +
          'ğŸŒŸ 2ì›” íŠ¹ë³„ ì´ë²¤íŠ¸\n' +
          'â€¢ íŒ+ì—¼ìƒ‰ ë™ì‹œ ì‹œìˆ  ì‹œ 20% í• ì¸\n' +
          'â€¢ ì‹ ê·œ ê³ ê° ì²« ë°©ë¬¸ 15% í• ì¸\n' +
          'â€¢ ì¹œêµ¬ ì¶”ì²œ ì‹œ ì–‘ìª½ ëª¨ë‘ 10,000ì› í• ì¸\n\n' +
          'ìì„¸í•œ ë‚´ìš©ì€ ì˜ˆì•½ ì‹œ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”!',
        confidence: 0.86,
      },
    ];

    // í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ìµœì  í…œí”Œë¦¿ ì°¾ê¸°
    let bestMatch: { response: string; confidence: number } | null = null;
    let bestScore = 0;

    for (const template of templates) {
      const matchCount = template.keywords.filter((kw) => text.includes(kw)).length;
      if (matchCount > bestScore) {
        bestScore = matchCount;
        bestMatch = { response: template.response, confidence: template.confidence };
      }
    }

    // ë§¤ì¹­ëœ í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ
    if (!bestMatch || bestScore === 0) {
      return {
        response:
          'ì•ˆë…•í•˜ì„¸ìš”, ë¸”ë£¸ í—¤ì–´ì‚´ë¡±ì…ë‹ˆë‹¤! ğŸ˜Š\n' +
          'ë¬¸ì˜í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.\n\n' +
          'ê¶ê¸ˆí•˜ì‹  ë‚´ìš©ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì‹œë©´ ë¹ ë¥´ê²Œ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n' +
          'ì˜ˆì•½, ê°€ê²©, ì˜ì—…ì‹œê°„ ë“± ë¬´ì—‡ì´ë“  í¸í•˜ê²Œ ë¬¼ì–´ë´ì£¼ì„¸ìš”!',
        confidence: 0.75,
      };
    }

    return bestMatch;
  }

  private async tryDeductCredits(
    tenantId: string,
    amount: number,
    description: string,
    referenceId: string,
    referenceType: string,
  ): Promise<void> {
    try {
      await this.creditService.deductCredits(tenantId, amount, description, referenceId, referenceType);
    } catch (error) {
      // Log but don't block the response - credit issues shouldn't prevent customer support
      this.logger.warn(`Credit deduction failed for tenant ${tenantId}: ${(error as Error).message}`);
    }
  }
}
